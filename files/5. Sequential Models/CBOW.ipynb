{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([48, 15, 18, 47])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "\n",
    "\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "\n",
    "print(data[:5])\n",
    "\n",
    "# create your model and train.  here are some functions to help you make\n",
    "# the data ready for use by your module\n",
    "\n",
    "\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    if type(context) is list:\n",
    "        idxs = [word_to_ix[w] for w in context]\n",
    "        return torch.tensor(idxs, dtype=torch.long)\n",
    "    else:\n",
    "        return torch.tensor([word_to_ix[context]], dtype=torch.long)\n",
    "\n",
    "\n",
    "make_context_vector(data[0][0], word_to_ix)  # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_word = {\n",
    "    word_to_ix[key]: key\n",
    "    for key in word_to_ix\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    return a.matmul(b.t()) / (a.norm() * b.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.activation_function1 = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.activation_function2 = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation_function1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation_function2(out)\n",
    "        return out\n",
    "\n",
    "    def get_embeddings(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(vocab_size, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48, 15, 18, 47]) tensor([28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.4192, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = make_context_vector(data[0][0], word_to_ix)\n",
    "target = torch.tensor([word_to_ix[data[0][1]]]).long()\n",
    "\n",
    "print(inputs, target)\n",
    "\n",
    "criterion(model(inputs), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/2000] Loss: 8.935628525912762\n",
      "[200/2000] Loss: 1.5286855399608612\n",
      "[300/2000] Loss: 0.6594539228826761\n",
      "[400/2000] Loss: 0.37290025083348155\n",
      "[500/2000] Loss: 0.24122070393059403\n",
      "[600/2000] Loss: 0.16917798144277185\n",
      "[700/2000] Loss: 0.12539086065953597\n",
      "[800/2000] Loss: 0.09662937436951324\n",
      "[900/2000] Loss: 0.07666986907133833\n",
      "[1000/2000] Loss: 0.06223645113641396\n",
      "[1100/2000] Loss: 0.05146561766741797\n",
      "[1200/2000] Loss: 0.04320472851395607\n",
      "[1300/2000] Loss: 0.03672436426859349\n",
      "[1400/2000] Loss: 0.03154755577270407\n",
      "[1500/2000] Loss: 0.027342620072886348\n",
      "[1600/2000] Loss: 0.023885776186943986\n",
      "[1700/2000] Loss: 0.021009747055359185\n",
      "[1800/2000] Loss: 0.018591526764794253\n",
      "[1900/2000] Loss: 0.016539772681426257\n",
      "[2000/2000] Loss: 0.014784213140956126\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "DISPLAY_EACH_EPOCH = 100\n",
    "EPOCHES = 2000\n",
    "\n",
    "losses = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    model.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        inputs = make_context_vector(context, word_to_ix)\n",
    "        target = torch.tensor([word_to_ix[target]]).long()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    if (epoch + 1) % DISPLAY_EACH_EPOCH == 0:\n",
    "        print('[%s/%s] Loss: %s' % (epoch + 1, EPOCHES, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb1cee66cc0>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embeddings): Embedding(49, 16)\n",
       "  (linear1): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (activation_function1): ReLU()\n",
       "  (linear2): Linear(in_features=128, out_features=49, bias=True)\n",
       "  (activation_function2): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_word(context, model):\n",
    "    \n",
    "    vector = model.get_embeddings(make_context_vector(context, word_to_ix))\n",
    "        \n",
    "    best_word = None\n",
    "    best_simy = -1\n",
    "    \n",
    "    for vword in vocab:\n",
    "        \n",
    "        if vword in context:\n",
    "            continue\n",
    "            \n",
    "        v = model.get_embeddings(make_context_vector(vword, word_to_ix))\n",
    "        \n",
    "        s = similarity(vector, v)\n",
    "        \n",
    "        if best_word is None:\n",
    "            best_word = vword\n",
    "            best_simy = s\n",
    "        \n",
    "        if s > best_simy:\n",
    "            best_word = vword\n",
    "            best_simy = s\n",
    "            \n",
    "    return best_word, best_simy.item()\n",
    "    \n",
    "\n",
    "def evaluate(context, model):\n",
    "    context_vector = make_context_vector(context, word_to_ix)\n",
    "    a = model(context_vector)\n",
    "\n",
    "    print(f'Context: {context}')\n",
    "    print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['People', 'study']\n",
      "Prediction: create\n",
      "\n",
      "\n",
      "Context: ['idea', 'process']\n",
      "Prediction: of\n",
      "\n",
      "\n",
      "Context: ['beings', 'People']\n",
      "Prediction: programs\n",
      "\n",
      "\n",
      "Context: ['pattern', 'process', 'computer']\n",
      "Prediction: about\n",
      "\n",
      "\n",
      "Context: ['computational']\n",
      "Prediction: a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\"\n",
    "\n",
    "\n",
    "evaluate(['People', 'study'], model)\n",
    "print('\\n')\n",
    "evaluate(['idea', 'process'], model)\n",
    "print('\\n')\n",
    "evaluate(['beings', 'People'], model)\n",
    "print('\\n')\n",
    "evaluate(['pattern', 'process', 'computer'], model)\n",
    "print('\\n')\n",
    "evaluate(['computational'], model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct ('manipulate', 0.48209720849990845)\n",
      "the ('about', 0.3668060302734375)\n",
      "by ('with', 0.5760161280632019)\n",
      "program. ('things', 0.4989606738090515)\n",
      "inhabit ('pattern', 0.5285772085189819)\n",
      "As ('conjure', 0.4363301992416382)\n",
      "spirits ('study', 0.7306721806526184)\n",
      "that ('evolution', 0.7505890727043152)\n",
      "evolution ('that', 0.7505890727043152)\n",
      "programs ('beings', 0.4174237549304962)\n",
      "The ('We', 0.5466554164886475)\n",
      "computational ('effect,', 0.48458290100097656)\n",
      "abstract ('things', 0.7316676378250122)\n",
      "other ('In', 0.37484100461006165)\n",
      "beings ('We', 0.5407030582427979)\n",
      "are ('evolve,', 0.5538862943649292)\n",
      "Computational ('directed', 0.7081249356269836)\n",
      "data. ('In', 0.6790127158164978)\n",
      "to ('conjure', 0.5540122389793396)\n",
      "computers. ('we', 0.6065623164176941)\n",
      "things ('abstract', 0.7316676378250122)\n",
      "manipulate ('direct', 0.48209720849990845)\n",
      "rules ('is', 0.5940141677856445)\n",
      "processes ('data.', 0.6587375998497009)\n",
      "process ('computational', 0.4451178312301636)\n",
      "a ('our', 0.41864243149757385)\n",
      "of ('abstract', 0.5979321002960205)\n",
      "is ('rules', 0.5940141677856445)\n",
      "about ('create', 0.4646230638027191)\n",
      "they ('processes.', 0.5289667248725891)\n",
      "People ('by', 0.5458078384399414)\n",
      "we ('computers.', 0.6065623164176941)\n",
      "idea ('rules', 0.5088858008384705)\n",
      "with ('by', 0.5760161280632019)\n",
      "conjure ('to', 0.5540122389793396)\n",
      "directed ('Computational', 0.7081249356269836)\n",
      "create ('about', 0.4646230638027191)\n",
      "our ('with', 0.4722086489200592)\n",
      "process. ('People', 0.5160688161849976)\n",
      "processes. ('abstract', 0.6158760786056519)\n",
      "evolve, ('pattern', 0.5866743326187134)\n",
      "called ('is', 0.5456210374832153)\n",
      "In ('data.', 0.6790127158164978)\n",
      "computer ('is', 0.4642002582550049)\n",
      "spells. ('processes.', 0.4467819333076477)\n",
      "effect, ('computational', 0.48458290100097656)\n",
      "pattern ('evolve,', 0.5866743326187134)\n",
      "study ('spirits', 0.7306721806526184)\n",
      "We ('The', 0.5466554164886475)\n"
     ]
    }
   ],
   "source": [
    "for word in vocab:\n",
    "    print(word, next_word([word], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
