{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 180107219 - Negmetulla Yerlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZBzA2SqTeA9",
    "outputId": "970c2232-76c0-4eac-91f8-2cedffe59f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q1_SyrUxHyRy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eM3qBfkvISNI"
   },
   "outputs": [],
   "source": [
    "file_path_list = glob.glob('drive/MyDrive/DeepLearningAssignment5/data/*.txt')\n",
    "\n",
    "full_text = \"\"\n",
    "if file_path_list:\n",
    "    with open(file_path_list[0], 'r') as f:\n",
    "        full_text += f.read()\n",
    "    for i in range(len(file_path_list)):\n",
    "        with open(file_path_list[i], 'r') as f:\n",
    "            full_text += \"\\n\" + f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-T-g7x26IbME"
   },
   "outputs": [],
   "source": [
    "chars = tuple(set(full_text))\n",
    "idx2char = dict(enumerate(chars))\n",
    "char2idx = {ch: ii for ii, ch in idx2char.items()}\n",
    "\n",
    "encoded = np.array([char2idx[ch] for ch in full_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RKM-j3KWIjFs"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F9z_XYL6IteN"
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lvzwzaHVI8J1"
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, chars, n_hidden=256, n_layers=3, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.chars = chars\n",
    "        self.idx2char = dict(enumerate(self.chars))\n",
    "        self.char2idx = {ch: ii for ii, ch in self.idx2char.items()}\n",
    "        self.lstm=nn.LSTM(len(self.chars),n_hidden,n_layers, dropout=drop_prob,batch_first=True)\n",
    "        self.dropout=nn.Dropout(drop_prob)\n",
    "        self.fc=nn.Linear(n_hidden,len(self.chars))\n",
    "    def forward(self, x, hidden):\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (\n",
    "            weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "            weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda()\n",
    "        )\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NytHgxMXdSG_"
   },
   "outputs": [],
   "source": [
    "def train(model, batch, h, criterion, optimizer, clip):\n",
    "    model.train()\n",
    "    x, y = batch\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    output, h = model(inputs, h)\n",
    "    loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dI9y3xEaJPBN"
   },
   "outputs": [],
   "source": [
    "def full_train(model, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, print_every=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    n_chars = len(model.chars)\n",
    "    model.cuda()\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        h = model.init_hidden(batch_size)\n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            loss = train(model, (x,y), h, criterion, optimizer, clip)\n",
    "            if counter % print_every == 0:\n",
    "                print(f\"Epoch: {e+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KSkBEXa8Ji9l"
   },
   "outputs": [],
   "source": [
    "n_hidden = 512\n",
    "n_layers = 3\n",
    "model = CharRNN(chars, n_hidden, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDVAEZMhZHtf",
    "outputId": "634c48ed-9816-4996-a688-f79da69e325d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('drive/MyDrive/DeepLearningAssignment5/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFulOEswJnam",
    "outputId": "05ea1b9d-5e67-46b4-abd4-663a81a7e435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500/5000, Loss: 1.0687\n",
      "Epoch: 1000/5000, Loss: 0.0872\n",
      "Epoch: 1500/5000, Loss: 0.0411\n",
      "Epoch: 2000/5000, Loss: 0.0303\n",
      "Epoch: 2500/5000, Loss: 0.0244\n",
      "Epoch: 3000/5000, Loss: 0.0246\n",
      "Epoch: 3500/5000, Loss: 0.0219\n",
      "Epoch: 4000/5000, Loss: 0.0208\n",
      "Epoch: 4500/5000, Loss: 0.0201\n",
      "Epoch: 5000/5000, Loss: 0.0211\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs =  5000\n",
    "full_train(model, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f2VnsR_GJsu1"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'drive/MyDrive/DeepLearningAssignment5/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ag5zz6tmJyFW"
   },
   "outputs": [],
   "source": [
    "def predict(model, char, h=None, top_k=None):\n",
    "    x = np.array([[model.char2idx[char]]])\n",
    "    x = one_hot_encode(x, len(model.chars))\n",
    "    inputs = torch.from_numpy(x)\n",
    "    inputs = inputs.cuda()\n",
    "    h = tuple([each.data for each in h])\n",
    "    out, h = model(inputs, h)\n",
    "    p = F.softmax(out, dim=1).data\n",
    "    p = p.cpu()\n",
    "    top_ch = np.arange(len(model.chars))\n",
    "    p = p.numpy().squeeze()\n",
    "    char = np.random.choice(top_ch, p=p/p.sum())\n",
    "    return model.idx2char[char], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VJJEsl74J3im"
   },
   "outputs": [],
   "source": [
    "def generate(nemodelt, prime='Мен', line_number=14):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    chars = [ch for ch in prime]\n",
    "    h = model.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(model, ch, h,)\n",
    "    chars.append(char)\n",
    "    n = 0; prev_ch = \"\"\n",
    "    while not (n >= line_number and prev_ch in \"?!.\") and line_number < 100:\n",
    "        char, h = predict(model, chars[-1], h)\n",
    "        chars.append(char)\n",
    "        if char == \"\\n\":\n",
    "            n += 1\n",
    "        prev_ch = char\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lskwWoOZKCY-",
    "outputId": "d1c81824-3bf3-45bf-d074-03714985d82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мен кей кұңса, \n",
      "Ақсалығы балқылдап. \n",
      "Жаледен қығыр айтақ қарғанға.\n",
      "Қай ақық қорғансыз шұй карбай.\n",
      "Қай атында  аппылдап, \n",
      "Арасында құлын-тай \n",
      "Айнала шауып бұлтылдап, \n",
      "пандынты тұр балаңғы \n",
      "Қал-ыңыші қалым алтқан \n",
      "Күліші шағып жұры тіл, \n",
      "Қалыққан барған пел тарған \n",
      "Асыа толған оңық қарғайдап асынпан \n",
      "Бер жаңған талтым бүр іуде жасынан.\n",
      "Ое үңіле көрі тоқса сотған қойға,\n",
      "Қар-- апық, бүркіт – өапең тон тағынға.\n",
      "Қайды тот - пашы үті  ылшы алға, \n",
      "Көренееі шіріп қалылып қойған дап \n",
      "Көріпер қарқаң босыса,\n",
      "Колынқыз көлі бор жерген \n",
      "Етім тініп тоңқалдап.\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, 'Мен', 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLamkzYLprBj",
    "outputId": "ecb7ac27-0c11-4bd4-925a-d43a59ca41c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Далалын \n",
      "Салпы тат  қарыптіт есее қалман.\n",
      "О да бол қасақ ақалда, моз барғанда. \n",
      "Аузын ашса, ыяқуқтап,\n",
      "Қасысын қалуындап,\n",
      "Бар баламын қылтылдап, \n",
      "Ат, айғырлар, биелер \n",
      "Бүйірші шығыы  бар жүлеп, \n",
      "Ақырығын балқын деп, \n",
      "Орынуыры қарасы қай, \n",
      "Жаныққандар, бәс еуеп, \n",
      "Астасын қанданға.\n",
      "Бар бала ашы  ылынып, \n",
      "Үлден ит пей айтаққа. \n",
      "Колмып па едің жол тосып \n",
      "Жолығуғғы шалып бал жібек \n",
      "ал жобанды.\n",
      "Қатда толған балтық шеп баршадан. \n",
      "Бар жешін ақтатай соғ алы сайғы.\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, 'Дала', 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mnq3SR6gcZN",
    "outputId": "116a85db-2328-49fb-eaf0-d996b694c80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мысал қысан адім азға а ша ар, қызар бал.\n",
      "Күйі тіп, тәрі шауда асық шынып.\n",
      "Жасы үшін күлітде сөл ау санға.\n",
      "Жасы аз патар етітсез қыр шан едес, \n",
      "Күйлесем, сөрдесем сен тармайда.\n",
      "Қай марым бір кімір сел імдемін.\n",
      "Бай масым бөрмерген сес белем, \n",
      "Жеп атпан катдан жүқ карша кесек.\n",
      "Көзін аует көздемес. \n",
      "Үттен де ұядшап,\n",
      "Қазлықын көлген де, қер шенем.\n",
      "Жандаң ешы қай емын сан барға, \n",
      "Балуан да ам,аршы меп, алқалда. \n",
      "Көрімішер сара қал патып дыпға.\n",
      "Мандан тоң ақ тізін, күйді тастап, \n",
      "Қалтықар кылып баз жерег, сысыл деп. \n",
      "Жендер өзыпқа қалы соң терпедім.\n",
      "Ере төрікде келек сонда.\n",
      "Қансақ күлген қошынған де - бірмерме,, \n",
      "Ықталма ас сап кем емім сез келім.\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, 'Мысал', 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhyYQB3vnY9c",
    "outputId": "948dd06b-a852-4127-e9c9-5db20ea7d24a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ой тіл аутағын.\n",
      "Қайды алын қолынып, біл қалшанға. \n",
      "Бұрғаны шалқын бімер ек ша шағын, \n",
      "От ағына  олдан, көр ееі жұры \n",
      "Қетірде толсың бос анау, \n",
      "Қалрынғы дас- бар бер, \n",
      "Қолсысынға кисіп бал, \n",
      "Санжайлы сап болтындай. \n",
      "Байғаншы еш, шабыйдап, \n",
      "Өзепін қасық солдар - бал, ақ асаа.\n",
      "Бүреді - бір ақылсан, Бұр ақанмай, \n",
      "Манақ бұлаң, босыны - өле сұрса, \n",
      "Таптағынтып болыны қылтылдан  \n",
      "Са солықбан бәлі -өз,,\n",
      "Қан ызылар  алығып.\n",
      "Кұл ақақа қосып таң едеп, \n",
      "Үлгенен балдап бір аутеп, \n",
      "Мандынар балған бой шауасқа.\n",
      "Бар - ақыл шаттан түркі жайыа еден.\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, 'Ой', 18))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "source1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
